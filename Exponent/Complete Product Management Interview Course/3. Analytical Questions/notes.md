# Analytical Questions [Execution/Product Insights]

1. Can you reason with metrics?
2. Can you think critically about user feedback and bugs?

Test your knowledge and comfort with -
1. Metrics
2. Statistics
3. Strategy
4. Execution
5. Debugging

## Questions

1. A/B Testing
2. Metrics and Data
3. Execution

## Question Type 1: A/B Testing

Sample Questions -
1. What are the top 3 types of A/B Experiments you would run on FB Ads to increase revenue?
2. How would you experiment with LinkedIn's Homepage to drive sign-in rate?


## Question Type 2: Metrics

Sample Questions -
1. What are Youtube's/Airbnb's Key Metrics?

### GAME Framework

- **Goal** - What is the goal for the product? Vision? Where do we see the product growing over the next 5 years?
- **Action** - What action do we want the user to take to support these goals? What features or actions drive engagement?
- **Metrics** - Which metrics capture these actions? Are the users taking the actions that align with the product's goals?
- **Evaluate** - Is this metric a FP or FN?

## Question Type 3: Execution

Sample Questions -
1. Facebook is experiencing a 6% decline in user base this month. What could be causing this decline? How would you investigate?
2. Walk through a launch day for a new Google search feature. What channels would you use to promote this feature on the day of the launch? Before? After?
3. How would you price a new competitor to the Amazon Alexa and Google Home? What factors would be important in your analysis?

Your answer should exhibit -
- Attention to detail
- Understanding of the tech industry (or related)
- Experience with shipping products
- Knowledge about debugging
- Technical Knowledge

## Common Errors

1. Not asking questions
2. Trying to get the correct answer - PM Interview Questions do NOT have the right answer - Feel free to be creative as heck!
3. Ignoring tradeoffs - Always mention them! Shows you have critical thinking and judgement abilities

## How to Answer A/B Testing Questions

- Core tool for understanding **USER BEHAVIOR**

### 1. Hypothesis - What are you testing?
- Increasing the size of the button will increase the CTR?

### 2. Methodology - How will you test it?
- Let's run 2 cohorts of users - 1 control, 1 with increased size of button
- Do you want to pick a customer segment, or all users?

### 3. Metrics - What metrics will you track?
- What metrics will convey useful insights to your product and engineering teams?

Eg.
1. Impression counts
2. CTR on other buttons on the page
3. Button hover time
4. Time spent on page
5. Bounce rate on the button's link

### 4. Impact - How will you use this information?
- What metrics will you use to make an informed decision about whether or not to launch the proposed feature?

### 5. Tradeoffs - What could go wrong?
- Potential pitfalls to launching your proposed feature?

## Rubric 

1. Data Literacy - Extract valuable insights from data, identify ket patterns, suggested reports/tests to run, logical arguments
2. Comfort with Metrics - User acquisition, retention, usage
3. Ability to diagnose problems - asking insightful questions, setting up a clear, easy-to-use test plan (Simplify EVERY interview question as much as possible - Nothing should be complicated)
4. Ability to Prioritize - Prioritise well. Proposed plan provides maximum benefit with minimal cost
5. Ability to Execute a Plan - Plan is clear and complete. Best-fit KPIs, bottlenecks/potential errors accounted for, alternatives given.
6. Communication - Clear, proactive, anticipated questions, check-in throughout.
7. Collaboration - Make use of the interviewer
8. Curiosity - Gather information effectively, asking insights and/or surprising questions that get to the heart of the issue
